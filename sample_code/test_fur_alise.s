	.section	__TEXT,__text,regular,pure_instructions
	.macosx_version_min 10, 14
	.globl	_generate_music         ## -- Begin function generate_music
	.p2align	4, 0x90
_generate_music:                        ## @generate_music
	.cfi_startproc
## %bb.0:                               ## %entry
	pushq	%rbx
	.cfi_def_cfa_offset 16
	subq	$32, %rsp
	.cfi_def_cfa_offset 48
	.cfi_offset %rbx, -16
	movl	%ecx, 28(%rsp)
	movl	%edx, 24(%rsp)
	movq	%rsi, 16(%rsp)
	movq	%rdi, 8(%rsp)
	leaq	L_123(%rip), %rdi
	xorl	%eax, %eax
	callq	_puts
	movl	28(%rsp), %esi
	leaq	L_fmt(%rip), %rbx
	movq	%rbx, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	24(%rsp), %esi
	movq	%rbx, %rdi
	xorl	%eax, %eax
	callq	_printf
	movl	$0, 4(%rsp)
	jmp	LBB0_1
	.p2align	4, 0x90
LBB0_2:                                 ## %while_body
                                        ##   in Loop: Header=BB0_1 Depth=1
	movq	16(%rsp), %rax
	movslq	4(%rsp), %rcx
	movq	(%rax,%rcx,8), %rdi
	xorl	%eax, %eax
	callq	_pitch_to_int
	movq	%rbx, %rdi
	movl	%eax, %esi
	xorl	%eax, %eax
	callq	_printf
	movq	8(%rsp), %rax
	movslq	4(%rsp), %rcx
	movl	(%rax,%rcx,4), %esi
	movq	%rbx, %rdi
	xorl	%eax, %eax
	callq	_printf
	incl	4(%rsp)
LBB0_1:                                 ## %while
                                        ## =>This Inner Loop Header: Depth=1
	movl	4(%rsp), %eax
	cmpl	24(%rsp), %eax
	jl	LBB0_2
## %bb.3:                               ## %merge
	addq	$32, %rsp
	popq	%rbx
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_build_track            ## -- Begin function build_track
	.p2align	4, 0x90
_build_track:                           ## @build_track
	.cfi_startproc
## %bb.0:                               ## %entry
	pushq	%rbx
	.cfi_def_cfa_offset 16
	subq	$80, %rsp
	.cfi_def_cfa_offset 96
	.cfi_offset %rbx, -16
	movq	%rdi, %rbx
	movl	%esi, 20(%rsp)
	movl	%edx, 16(%rsp)
	movq	%rcx, 48(%rsp)
	movq	%r8, 40(%rsp)
	movl	$160, %edi
	callq	_malloc
	leaq	"L_4#"(%rip), %rcx
	movq	%rcx, (%rax)
	leaq	"L_4#.4"(%rip), %rcx
	movq	%rcx, 8(%rax)
	leaq	"L_4#.5"(%rip), %rcx
	movq	%rcx, 16(%rax)
	leaq	"L_4#.6"(%rip), %rcx
	movq	%rcx, 24(%rax)
	leaq	"L_4#.7"(%rip), %rcx
	movq	%rcx, 32(%rax)
	leaq	"L_4#.8"(%rip), %rcx
	movq	%rcx, 40(%rax)
	leaq	"L_4#.9"(%rip), %rcx
	movq	%rcx, 48(%rax)
	leaq	"L_4#.10"(%rip), %rcx
	movq	%rcx, 56(%rax)
	leaq	"L_4#.11"(%rip), %rcx
	movq	%rcx, 64(%rax)
	leaq	"L_4#.12"(%rip), %rcx
	movq	%rcx, 72(%rax)
	leaq	"L_4#.13"(%rip), %rcx
	movq	%rcx, 80(%rax)
	leaq	"L_4#.14"(%rip), %rcx
	movq	%rcx, 88(%rax)
	leaq	"L_4#.15"(%rip), %rcx
	movq	%rcx, 96(%rax)
	leaq	"L_4#.16"(%rip), %rcx
	movq	%rcx, 104(%rax)
	leaq	"L_4#.17"(%rip), %rcx
	movq	%rcx, 112(%rax)
	leaq	"L_4#.18"(%rip), %rcx
	movq	%rcx, 120(%rax)
	leaq	"L_4#.19"(%rip), %rcx
	movq	%rcx, 128(%rax)
	leaq	"L_4#.20"(%rip), %rcx
	movq	%rcx, 136(%rax)
	leaq	"L_4#.21"(%rip), %rcx
	movq	%rcx, 144(%rax)
	leaq	"L_4#.22"(%rip), %rcx
	movq	%rcx, 152(%rax)
	movq	%rax, 32(%rsp)
	movl	$80, %edi
	callq	_malloc
	movq	$0, (%rax)
	movq	$0, 8(%rax)
	movq	$0, 16(%rax)
	movq	$0, 24(%rax)
	movq	$0, 32(%rax)
	movq	$0, 40(%rax)
	movq	$0, 48(%rax)
	movq	$0, 56(%rax)
	movq	$0, 64(%rax)
	movq	$0, 72(%rax)
	movq	%rax, 24(%rsp)
	movl	20(%rsp), %eax
	movl	%eax, 76(%rsp)
	movl	16(%rsp), %eax
	movl	%eax, 72(%rsp)
	movl	$0, 12(%rsp)
	jmp	LBB1_1
	.p2align	4, 0x90
LBB1_2:                                 ## %while_body
                                        ##   in Loop: Header=BB1_1 Depth=1
	movq	48(%rsp), %rax
	movslq	12(%rsp), %rcx
	movq	(%rax,%rcx,8), %rax
	movq	32(%rsp), %rdx
	movq	%rax, (%rdx,%rcx,8)
	movq	40(%rsp), %rax
	movslq	12(%rsp), %rcx
	movl	(%rax,%rcx,4), %eax
	movq	24(%rsp), %rdx
	movl	%eax, (%rdx,%rcx,4)
	incl	12(%rsp)
LBB1_1:                                 ## %while
                                        ## =>This Inner Loop Header: Depth=1
	movl	12(%rsp), %eax
	cmpl	16(%rsp), %eax
	jl	LBB1_2
## %bb.3:                               ## %merge
	movq	32(%rsp), %rax
	movq	%rax, 64(%rsp)
	movq	24(%rsp), %rcx
	movq	%rcx, 56(%rsp)
	movq	72(%rsp), %rdx
	movq	%rdx, 16(%rbx)
	movq	%rax, 8(%rbx)
	movq	%rcx, (%rbx)
	movq	%rbx, %rax
	addq	$80, %rsp
	popq	%rbx
	retq
	.cfi_endproc
                                        ## -- End function
	.globl	_main                   ## -- Begin function main
	.p2align	4, 0x90
_main:                                  ## @main
	.cfi_startproc
## %bb.0:                               ## %entry
	pushq	%r15
	.cfi_def_cfa_offset 16
	pushq	%r14
	.cfi_def_cfa_offset 24
	pushq	%rbx
	.cfi_def_cfa_offset 32
	subq	$144, %rsp
	.cfi_def_cfa_offset 176
	.cfi_offset %rbx, -32
	.cfi_offset %r14, -24
	.cfi_offset %r15, -16
	movl	$16, %edi
	callq	_malloc
	leaq	"L_4#.25"(%rip), %rcx
	movq	%rcx, (%rax)
	leaq	"L_4#.26"(%rip), %rcx
	movq	%rcx, 8(%rax)
	movq	%rax, 24(%rsp)
	movl	$48, %edi
	callq	_malloc
	leaq	"L_4#.27"(%rip), %rcx
	movq	%rcx, (%rax)
	leaq	"L_4#.28"(%rip), %rcx
	movq	%rcx, 8(%rax)
	leaq	"L_4#.29"(%rip), %rcx
	movq	%rcx, 16(%rax)
	leaq	"L_4#.30"(%rip), %rcx
	movq	%rcx, 24(%rax)
	leaq	"L_4#.31"(%rip), %rcx
	movq	%rcx, 32(%rax)
	leaq	"L_4#.32"(%rip), %rcx
	movq	%rcx, 40(%rax)
	movq	%rax, 8(%rsp)
	movl	$40, %edi
	callq	_malloc
	leaq	"L_4#.33"(%rip), %rcx
	movq	%rcx, (%rax)
	leaq	"L_4#.34"(%rip), %rcx
	movq	%rcx, 8(%rax)
	leaq	"L_4#.35"(%rip), %rcx
	movq	%rcx, 16(%rax)
	leaq	"L_4#.36"(%rip), %rcx
	movq	%rcx, 24(%rax)
	leaq	"L_4#.37"(%rip), %rcx
	movq	%rcx, 32(%rax)
	movq	%rax, 40(%rsp)
	movl	$40, %edi
	callq	_malloc
	leaq	"L_4#.38"(%rip), %rcx
	movq	%rcx, (%rax)
	leaq	"L_4#.39"(%rip), %rcx
	movq	%rcx, 8(%rax)
	leaq	"L_4#.40"(%rip), %rcx
	movq	%rcx, 16(%rax)
	leaq	"L_4#.41"(%rip), %rcx
	movq	%rcx, 24(%rax)
	leaq	"L_4#.42"(%rip), %rcx
	movq	%rcx, 32(%rax)
	movq	%rax, 56(%rsp)
	movl	$8, %edi
	callq	_malloc
	leaq	"L_4#.43"(%rip), %rcx
	movq	%rcx, (%rax)
	movq	%rax, 80(%rsp)
	movl	$8, %edi
	callq	_malloc
	movabsq	$68719476752, %rbx      ## imm = 0x1000000010
	movq	%rbx, (%rax)
	movq	%rax, 16(%rsp)
	movl	$24, %edi
	callq	_malloc
	movq	%rbx, (%rax)
	movq	%rbx, 8(%rax)
	movq	%rbx, 16(%rax)
	movq	%rax, (%rsp)
	movl	$20, %edi
	callq	_malloc
	movabsq	$68719476744, %r14      ## imm = 0x1000000008
	movq	%r14, (%rax)
	movq	%rbx, 8(%rax)
	movl	$16, 16(%rax)
	movq	%rax, 32(%rsp)
	movl	$20, %edi
	callq	_malloc
	movq	%r14, (%rax)
	movq	%rbx, 8(%rax)
	movl	$16, 16(%rax)
	movq	%rax, 48(%rsp)
	movl	$4, %edi
	callq	_malloc
	movl	$8, (%rax)
	movq	%rax, 72(%rsp)
	movl	$152, %edi
	callq	_malloc
	movq	%rax, %r14
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	(%r15), %rax
	movq	%rax, (%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	8(%r15), %rax
	movq	%rax, 8(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	16(%r15), %rax
	movq	%rax, 16(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	24(%r15), %rax
	movq	%rax, 24(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	32(%r15), %rax
	movq	%rax, 32(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	40(%r15), %rax
	movq	%rax, 40(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	48(%r15), %rax
	movq	%rax, 48(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	56(%r15), %rax
	movq	%rax, 56(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	64(%r15), %rax
	movq	%rax, 64(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	72(%r15), %rax
	movq	%rax, 72(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	80(%r15), %rax
	movq	%rax, 80(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	88(%r15), %rax
	movq	%rax, 88(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	96(%r15), %rax
	movq	%rax, 96(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 112(%r15)
	movq	56(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 120(%r15)
	movq	56(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 128(%r15)
	movq	56(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 136(%r15)
	movq	%rax, 104(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 120(%r15)
	movq	56(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 128(%r15)
	movq	56(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 136(%r15)
	movq	%rax, 112(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 128(%r15)
	movq	56(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 136(%r15)
	movq	%rax, 120(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 136(%r15)
	movq	%rax, 128(%r14)
	movl	$144, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	(%rbx), %rax
	movq	%rax, (%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	8(%rbx), %rax
	movq	%rax, 8(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	16(%rbx), %rax
	movq	%rax, 16(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	24(%rbx), %rax
	movq	%rax, 24(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	32(%rbx), %rax
	movq	%rax, 32(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	40(%rbx), %rax
	movq	%rax, 40(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	48(%rbx), %rax
	movq	%rax, 48(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	56(%rbx), %rax
	movq	%rax, 56(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 64(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 72(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 80(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 96(%rbx)
	movq	%rax, 88(%r15)
	movl	$104, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	(%rax), %rax
	movq	%rax, (%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	8(%rax), %rax
	movq	%rax, 8(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	16(%rax), %rax
	movq	%rax, 16(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rdx
	movq	16(%rdx), %rdx
	movq	%rdx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 24(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rdx
	movq	24(%rdx), %rdx
	movq	%rdx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 32(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rdx
	movq	32(%rdx), %rdx
	movq	%rdx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 40(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rdx
	movq	40(%rdx), %rdx
	movq	%rdx, 56(%rax)
	movq	%rcx, 48(%rbx)
	movl	$64, %edi
	callq	_malloc
	movq	24(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, (%rax)
	movq	24(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 8(%rax)
	movq	8(%rsp), %rcx
	movq	(%rcx), %rcx
	movq	%rcx, 16(%rax)
	movq	8(%rsp), %rcx
	movq	8(%rcx), %rcx
	movq	%rcx, 24(%rax)
	movq	8(%rsp), %rcx
	movq	16(%rcx), %rcx
	movq	%rcx, 32(%rax)
	movq	8(%rsp), %rcx
	movq	24(%rcx), %rcx
	movq	%rcx, 40(%rax)
	movq	8(%rsp), %rcx
	movq	32(%rcx), %rcx
	movq	%rcx, 48(%rax)
	movq	8(%rsp), %rcx
	movq	40(%rcx), %rcx
	movq	%rcx, 56(%rax)
	movq	%rcx, 56(%rbx)
	movq	40(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 64(%rbx)
	movq	40(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 72(%rbx)
	movq	40(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 80(%rbx)
	movq	40(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 88(%rbx)
	movq	40(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 96(%rbx)
	movq	%rax, 96(%r15)
	movq	56(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 104(%r15)
	movq	56(%rsp), %rax
	movq	8(%rax), %rax
	movq	%rax, 112(%r15)
	movq	56(%rsp), %rax
	movq	16(%rax), %rax
	movq	%rax, 120(%r15)
	movq	56(%rsp), %rax
	movq	24(%rax), %rax
	movq	%rax, 128(%r15)
	movq	56(%rsp), %rax
	movq	32(%rax), %rax
	movq	%rax, 136(%r15)
	movq	%rax, 136(%r14)
	movq	80(%rsp), %rax
	movq	(%rax), %rax
	movq	%rax, 144(%r14)
	movq	%r14, 64(%rsp)
	movl	$76, %edi
	callq	_malloc
	movq	%rax, %r14
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	(%r15), %eax
	movl	%eax, (%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	4(%r15), %eax
	movl	%eax, 4(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	8(%r15), %eax
	movl	%eax, 8(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	12(%r15), %eax
	movl	%eax, 12(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	16(%r15), %eax
	movl	%eax, 16(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	20(%r15), %eax
	movl	%eax, 20(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	24(%r15), %eax
	movl	%eax, 24(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	28(%r15), %eax
	movl	%eax, 28(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	32(%r15), %eax
	movl	%eax, 32(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	36(%r15), %eax
	movl	%eax, 36(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	40(%r15), %eax
	movl	%eax, 40(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	44(%r15), %eax
	movl	%eax, 44(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	48(%r15), %eax
	movl	%eax, 48(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 56(%r15)
	movq	48(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 60(%r15)
	movq	48(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 64(%r15)
	movq	48(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 68(%r15)
	movl	%eax, 52(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 60(%r15)
	movq	48(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 64(%r15)
	movq	48(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 68(%r15)
	movl	%eax, 56(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 64(%r15)
	movq	48(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 68(%r15)
	movl	%eax, 60(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 68(%r15)
	movl	%eax, 64(%r14)
	movl	$72, %edi
	callq	_malloc
	movq	%rax, %r15
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	(%rbx), %eax
	movl	%eax, (%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	4(%rbx), %eax
	movl	%eax, 4(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	8(%rbx), %eax
	movl	%eax, 8(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	12(%rbx), %eax
	movl	%eax, 12(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	16(%rbx), %eax
	movl	%eax, 16(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	20(%rbx), %eax
	movl	%eax, 20(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	24(%rbx), %eax
	movl	%eax, 24(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	28(%rbx), %eax
	movl	%eax, 28(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 32(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 36(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 40(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 48(%rbx)
	movl	%eax, 44(%r15)
	movl	$52, %edi
	callq	_malloc
	movq	%rax, %rbx
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	(%rax), %eax
	movl	%eax, (%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	4(%rax), %eax
	movl	%eax, 4(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	8(%rax), %eax
	movl	%eax, 8(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rdx
	movl	8(%rdx), %edx
	movl	%edx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 12(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rdx
	movl	12(%rdx), %edx
	movl	%edx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 16(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rdx
	movl	16(%rdx), %edx
	movl	%edx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 20(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rdx
	movl	20(%rdx), %edx
	movl	%edx, 28(%rax)
	movl	%ecx, 24(%rbx)
	movl	$32, %edi
	callq	_malloc
	movq	16(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, (%rax)
	movq	16(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 4(%rax)
	movq	(%rsp), %rcx
	movl	(%rcx), %ecx
	movl	%ecx, 8(%rax)
	movq	(%rsp), %rcx
	movl	4(%rcx), %ecx
	movl	%ecx, 12(%rax)
	movq	(%rsp), %rcx
	movl	8(%rcx), %ecx
	movl	%ecx, 16(%rax)
	movq	(%rsp), %rcx
	movl	12(%rcx), %ecx
	movl	%ecx, 20(%rax)
	movq	(%rsp), %rcx
	movl	16(%rcx), %ecx
	movl	%ecx, 24(%rax)
	movq	(%rsp), %rcx
	movl	20(%rcx), %ecx
	movl	%ecx, 28(%rax)
	movl	%ecx, 28(%rbx)
	movq	32(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 32(%rbx)
	movq	32(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 36(%rbx)
	movq	32(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 40(%rbx)
	movq	32(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 44(%rbx)
	movq	32(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 48(%rbx)
	movl	%eax, 48(%r15)
	movq	48(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 52(%r15)
	movq	48(%rsp), %rax
	movl	4(%rax), %eax
	movl	%eax, 56(%r15)
	movq	48(%rsp), %rax
	movl	8(%rax), %eax
	movl	%eax, 60(%r15)
	movq	48(%rsp), %rax
	movl	12(%rax), %eax
	movl	%eax, 64(%r15)
	movq	48(%rsp), %rax
	movl	16(%rax), %eax
	movl	%eax, 68(%r15)
	movl	%eax, 68(%r14)
	movq	72(%rsp), %rax
	movl	(%rax), %eax
	movl	%eax, 72(%r14)
	movq	%r14, 136(%rsp)
	movq	64(%rsp), %rcx
	leaq	88(%rsp), %rdi
	movl	$1, %esi
	movl	$19, %edx
	movq	%r14, %r8
	callq	_build_track
	movq	88(%rsp), %rdi
	movq	96(%rsp), %rsi
	movq	104(%rsp), %rdx
	movq	%rdx, 128(%rsp)
	movq	%rsi, 120(%rsp)
	movq	%rdi, 112(%rsp)
	movl	132(%rsp), %ecx
                                        ## kill: def $edx killed $edx killed $rdx
	callq	_generate_music
	xorl	%eax, %eax
	addq	$144, %rsp
	popq	%rbx
	popq	%r14
	popq	%r15
	retq
	.cfi_endproc
                                        ## -- End function
	.section	__TEXT,__cstring,cstring_literals
L_fmt:                                  ## @fmt
	.asciz	"%d\n"

L_fmt.1:                                ## @fmt.1
	.asciz	"%g\n"

L_123:                                  ## @"123"
	.asciz	"track_start"

L_fmt.2:                                ## @fmt.2
	.asciz	"%d\n"

L_fmt.3:                                ## @fmt.3
	.asciz	"%g\n"

"L_4#":                                 ## @"4#"
	.asciz	"1b1"

"L_4#.4":                               ## @"4#.4"
	.asciz	"1b1"

"L_4#.5":                               ## @"4#.5"
	.asciz	"1b1"

"L_4#.6":                               ## @"4#.6"
	.asciz	"1b1"

"L_4#.7":                               ## @"4#.7"
	.asciz	"1b1"

"L_4#.8":                               ## @"4#.8"
	.asciz	"1b1"

"L_4#.9":                               ## @"4#.9"
	.asciz	"1b1"

"L_4#.10":                              ## @"4#.10"
	.asciz	"1b1"

"L_4#.11":                              ## @"4#.11"
	.asciz	"1b1"

"L_4#.12":                              ## @"4#.12"
	.asciz	"1b1"

"L_4#.13":                              ## @"4#.13"
	.asciz	"1b1"

"L_4#.14":                              ## @"4#.14"
	.asciz	"1b1"

"L_4#.15":                              ## @"4#.15"
	.asciz	"1b1"

"L_4#.16":                              ## @"4#.16"
	.asciz	"1b1"

"L_4#.17":                              ## @"4#.17"
	.asciz	"1b1"

"L_4#.18":                              ## @"4#.18"
	.asciz	"1b1"

"L_4#.19":                              ## @"4#.19"
	.asciz	"1b1"

"L_4#.20":                              ## @"4#.20"
	.asciz	"1b1"

"L_4#.21":                              ## @"4#.21"
	.asciz	"1b1"

"L_4#.22":                              ## @"4#.22"
	.asciz	"1b1"

L_fmt.23:                               ## @fmt.23
	.asciz	"%d\n"

L_fmt.24:                               ## @fmt.24
	.asciz	"%g\n"

"L_4#.25":                              ## @"4#.25"
	.asciz	"3^5"

"L_4#.26":                              ## @"4#.26"
	.asciz	"2#5"

"L_4#.27":                              ## @"4#.27"
	.asciz	"3^5"

"L_4#.28":                              ## @"4#.28"
	.asciz	"2#5"

"L_4#.29":                              ## @"4#.29"
	.asciz	"3^5"

"L_4#.30":                              ## @"4#.30"
	.asciz	"7^4"

"L_4#.31":                              ## @"4#.31"
	.asciz	"2^5"

"L_4#.32":                              ## @"4#.32"
	.asciz	"1^5"

"L_4#.33":                              ## @"4#.33"
	.asciz	"6^4"

"L_4#.34":                              ## @"4#.34"
	.asciz	"1b1"

"L_4#.35":                              ## @"4#.35"
	.asciz	"1^4"

"L_4#.36":                              ## @"4#.36"
	.asciz	"3^4"

"L_4#.37":                              ## @"4#.37"
	.asciz	"6^4"

"L_4#.38":                              ## @"4#.38"
	.asciz	"7^4"

"L_4#.39":                              ## @"4#.39"
	.asciz	"1b1"

"L_4#.40":                              ## @"4#.40"
	.asciz	"3^5"

"L_4#.41":                              ## @"4#.41"
	.asciz	"5#4"

"L_4#.42":                              ## @"4#.42"
	.asciz	"7^4"

"L_4#.43":                              ## @"4#.43"
	.asciz	"1^5"


.subsections_via_symbols
